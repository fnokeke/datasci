{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recommendation System Datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "This notebook uses the following datasets:\n",
    "\n",
    "- [MovieLens 10M data set](http://grouplens.org/datasets/movielens/10m/)\n",
    "- [MovieLens 22M data set](http://grouplens.org/datasets/movielens/latest/)\n",
    "- [Million song data set](http://labrosa.ee.columbia.edu/millionsong/tasteprofile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split dataset into 60-20-20 train-validate-test partitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "def exists(filepath):\n",
    "    return os.path.exists(filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 1043656\r\n",
      "-rw-r--r--@ 1 fnokeke  staff      11563 Jan 29 10:38 README.html\r\n",
      "-rwxr-x---@ 1 fnokeke  staff        753 Jan  5  2009 \u001b[31mallbut.pl\u001b[m\u001b[m\r\n",
      "-rw-r--r--@ 1 fnokeke  staff     522197 Jan  5  2009 movies.dat\r\n",
      "-rw-r--r--@ 1 fnokeke  staff  265105635 Jan  5  2009 ratings.dat\r\n",
      "-rwxr-x---@ 1 fnokeke  staff       1304 Feb 16 10:06 \u001b[31msplit_ratings.sh\u001b[m\u001b[m\r\n",
      "-rw-r--r--@ 1 fnokeke  staff    3584119 Jan  5  2009 tags.dat\r\n",
      "-rw-r--r--  1 fnokeke  staff   51584300 Apr  6 11:43 test20.dat\r\n",
      "-rw-r--r--  1 fnokeke  staff  161529860 Apr  6 11:43 train60.dat\r\n",
      "-rw-r--r--  1 fnokeke  staff   51990078 Apr  6 11:43 validation20.dat\r\n"
     ]
    }
   ],
   "source": [
    "# show current files\n",
    "!ls -l ml-10M100K/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Already created files: train60.dat, validation20.dat, test20.dat\n"
     ]
    }
   ],
   "source": [
    "if (exists('ml-10M100K/train60.dat') and exists('ml-10M100K/validation20.dat') and exists('ml-10M100K/test20.dat')):\n",
    "    print \"Already created files: train60.dat, validation20.dat, test20.dat\"    \n",
    "\n",
    "else:\n",
    "    # sort by timestamp (4th column)\n",
    "    print 'sorting file...'\n",
    "    !sort -t ':' -k4 ml-10M100K/ratings.dat > ml-10M100K/new_ratings.dat \n",
    "    print \"sorting complete.\"\n",
    "    \n",
    "    # split into 5 parts of 2 million each: train(3 parts), validation (1 part), test (1 part)\n",
    "    print \"splitting file...\"\n",
    "    !split -l 2000000 ml-10M100K/new_ratings.dat ff\n",
    "    !cat ffaa ffab ffac > ml-10M100K/train60.dat\n",
    "    !mv ffad ml-10M100K/validation20.dat\n",
    "    !mv ffae ml-10M100K/test20.dat\n",
    "    \n",
    "    # remove tmp files used to create partitions\n",
    "    !rm new_ratings.dat ff*\n",
    "    print \"splitting complete.\"    \n",
    "    print \"Newly created files: train60.dat, validation20.dat, test20.dat\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using train data, learn ALS model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import contextlib\n",
    "import itertools\n",
    "from math import sqrt\n",
    "from operator import add\n",
    "import sys\n",
    "\n",
    "from docopt import docopt\n",
    "from pyspark import SparkConf, SparkContext\n",
    "from pyspark.mllib.recommendation import ALS\n",
    "from pyspark.mllib.recommendation import Rating\n",
    "\n",
    "\n",
    "SPARK_EXECUTOR_MEMORY = '6g'\n",
    "SPARK_APP_NAME = 'movieRecommender'\n",
    "SPARK_MASTER = 'local'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "@contextlib.contextmanager\n",
    "def spark_manager():\n",
    "    conf = SparkConf().setMaster(SPARK_MASTER) \\\n",
    "                      .setAppName(SPARK_APP_NAME) \\\n",
    "                      .set(\"spark.executor.memory\", SPARK_EXECUTOR_MEMORY)\n",
    "    spark_context = SparkContext(conf=conf)\n",
    "\n",
    "    try:\n",
    "        yield spark_context\n",
    "    finally:\n",
    "        spark_context.stop()\n",
    "\n",
    "\n",
    "\n",
    "def parse_rating(line):\n",
    "    \"\"\"\n",
    "    Parses a rating record that's in MovieLens format.\n",
    "    \n",
    "    :param str line: userId::movieId::rating::timestamp\n",
    "    \"\"\"\n",
    "    fields = line.strip().split(\"::\")\n",
    "\n",
    "    return (int(fields[0]),   # User ID\n",
    "            int(fields[1]),   # Movie ID\n",
    "            float(fields[2])) # Rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "context = spark_manager()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "training = sc.textFile('ml-10M100K/train60.dat') \\\n",
    "         .filter(lambda x: x and len(x.split('::')) == 4) \\\n",
    "         .map(parse_rating)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "validation = sc.textFile('ml-10M100K/validation20.dat') \\\n",
    "         .filter(lambda x: x and len(x.split('::')) == 4) \\\n",
    "         .map(parse_rating)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test = sc.textFile('ml-10M100K/test20.dat') \\\n",
    "         .filter(lambda x: x and len(x.split('::')) == 4) \\\n",
    "         .map(parse_rating)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6000000"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainCount = training.count()\n",
    "trainCount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2000000"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validationCount = validation.count()\n",
    "validationCount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2000000"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testCount = test.count()\n",
    "testCount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on method train in module pyspark.mllib.recommendation:\n",
      "\n",
      "train(cls, ratings, rank, iterations=5, lambda_=0.01, blocks=-1, nonnegative=False, seed=None) method of __builtin__.type instance\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(ALS.train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Meaning of parameters\n",
    "\n",
    "- numBlocks is the number of blocks used to parallelize computation (set to -1 to auto-configure).\n",
    "- ***rank*** is the number of latent factors in the model.\n",
    "- iterations is the number of iterations to run.\n",
    "- ***lambda*** specifies the regularization parameter in ALS.\n",
    "- implicitPrefs specifies whether to use the explicit feedback ALS variant or one adapted for implicit feedback data.\n",
    "- alpha is a parameter applicable to the implicit feedback variant of ALS that governs the baseline confidence in preference observations.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(37746, 3409, 0.5), (37746, 175, 0.5), (51778, 5430, 0.5)]"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training.take(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(6352, 6787, 4.0), (26571, 1580, 4.0), (26571, 2115, 4.0)]"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validation.take(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(5337, 296, 4.0), (5337, 307, 4.0), (32329, 3745, 4.0)]"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.take(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train and Save ALS Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model = ALS.train(training, 10, 20, 0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.save(sc, 'myALSmodel')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Try model with validation set (user-product pairs needed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on method predictAll in module pyspark.mllib.recommendation:\n",
      "\n",
      "predictAll(self, user_product) method of pyspark.mllib.recommendation.MatrixFactorizationModel instance\n",
      "    Returns a list of predicted ratings for input user and product pairs.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(model.predictAll)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(6352, 6787), (26571, 1580), (26571, 2115)]"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validation_pair = validation.map(lambda x: (x[0], x[1]))\n",
    "validation_pair.take(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Rating(user=57436, product=1356, rating=2.9622857548829815),\n",
       " Rating(user=57436, product=648, rating=2.7055366122842517),\n",
       " Rating(user=57436, product=260, rating=2.618657352015365)]"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = model.predictAll(validation_pair)\n",
    "predictions.take(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(57436, 1356, 2.9622857548829815),\n",
       " (57436, 648, 2.7055366122842517),\n",
       " (57436, 260, 2.618657352015365)]"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = predictions.map(lambda x: (x[0], x[1], x[2]))\n",
    "predictions.take(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute Mean Squared Error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(65538, (34, 432)), (65538, (34, 376)), (65538, (34, 592))]"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratesAndPreds = training.join(predictions)\n",
    "ratesAndPreds.take(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(65538, (34, 432)),\n",
       " (65538, (34, 376)),\n",
       " (65538, (34, 592)),\n",
       " (65538, (34, 224)),\n",
       " (65538, (34, 440)),\n",
       " (65538, (34, 256)),\n",
       " (65538, (34, 349)),\n",
       " (65538, (34, 281)),\n",
       " (65538, (34, 153)),\n",
       " (65538, (34, 457)),\n",
       " (65538, (34, 5)),\n",
       " (65538, (34, 593)),\n",
       " (65538, (34, 105))]"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratesAndPreds.take(13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[158404, 116964, 311364, 36100, 164836, 49284, 99225, 61009, 14161, 178929]"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MSE = ratesAndPreds.map(lambda r: (r[1][0] - r[1][1])**2)\n",
    "MSE.take(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "124643018399371127"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MSE.reduce(add)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "482038959"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MSE.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Root Mean Squared Error = 0.732405907908\n"
     ]
    }
   ],
   "source": [
    "RMSE = sqrt(124643018399371127)/482038959.0\n",
    "print(\"Root Mean Squared Error = \" + str(RMSE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using validation data, choose different regularization parameters with different latent factors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using test data, test chosen model and report metric error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Use ALS model and ratings file to return output of predicted recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generate_recommendations(modelALS, ratings):\n",
    "    prediction = []\n",
    "    return prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
