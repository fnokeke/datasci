{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import random\n",
    "import os.path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import csv\n",
    "\n",
    "from pyspark.sql import SQLContext, Row\n",
    "from pyspark.sql.types import *\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('fivethirtyeight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# TODO: handle different types of NaN in different columns\n",
    "# handle NAN for integers and check for '' or \" \""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def exists(filepath):\n",
    "    return os.path.exists(filepath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split 48 million rows to 10 million(training) & 38 million(testing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train10M.txt and test38M.txt already created before.\n"
     ]
    }
   ],
   "source": [
    "if (exists('train10M.txt') and exists('test38M.txt')):\n",
    "    print \"train10M.txt and test38M.txt already created before.\"\n",
    "else:\n",
    "    #!split -l 2000000 train.txt ff\n",
    "    #!cat ffaa ffat ffaf ffaq ffaj > train10M.txt\n",
    "    #!rm ffaa ffat ffaf ffaq ffaj\n",
    "    #!cat ff* > test38M.txt\n",
    "    #!rm ff*\n",
    "    print \"Newly created files: train10M.txt and test38M.txt.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split training data into 3 partitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train5M.txt, validation2M.txt, test3M.txt already created before.\n"
     ]
    }
   ],
   "source": [
    "if (exists('train5M.txt') and \n",
    "    exists('validation2M.txt') and \n",
    "    exists('test3M.txt')):\n",
    "    print \"train5M.txt, validation2M.txt, test3M.txt already created before.\"\n",
    "else:\n",
    "    !split -l 1000000 train10M.txt ff\n",
    "    !cat ffaa ffaj ffad ffaf ffah > train5M.txt    \n",
    "    !cat ffai ffae > validation2M.txt\n",
    "    !cat ffac ffag ffab > test3M.txt\n",
    "    !rm ff*\n",
    "    print \"Newly created files: train5M.txt, validation2M.txt, test3M.txt.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Perform training and analysis with train5M data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4999999, 40)\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_table('train5M.txt')\n",
    "print df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Remove and save the first column as y "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y = df['0']\n",
    "y.to_csv('y_for_train5M.csv', index=False)\n",
    "df = df.drop('0', 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Rename column for train5m data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "new_col_names = ['f' + str(num) for num in range(1,len(df.columns)+1)]\n",
    "df.columns = new_col_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get summary stats for all integer columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>f1</th>\n",
       "      <th>f2</th>\n",
       "      <th>f3</th>\n",
       "      <th>f4</th>\n",
       "      <th>f5</th>\n",
       "      <th>f6</th>\n",
       "      <th>f7</th>\n",
       "      <th>f8</th>\n",
       "      <th>f9</th>\n",
       "      <th>f10</th>\n",
       "      <th>f11</th>\n",
       "      <th>f12</th>\n",
       "      <th>f13</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>2756813.000000</td>\n",
       "      <td>4999999.000000</td>\n",
       "      <td>3906401.000000</td>\n",
       "      <td>3853777.000000</td>\n",
       "      <td>4863896.000000</td>\n",
       "      <td>3887221.000000</td>\n",
       "      <td>4788996.000000</td>\n",
       "      <td>4997037.000000</td>\n",
       "      <td>4788996.000000</td>\n",
       "      <td>2756813.000000</td>\n",
       "      <td>4788996.000000</td>\n",
       "      <td>1177668.000000</td>\n",
       "      <td>3853777.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>3.550075</td>\n",
       "      <td>98.595417</td>\n",
       "      <td>30.839373</td>\n",
       "      <td>7.429061</td>\n",
       "      <td>18112.661813</td>\n",
       "      <td>118.854952</td>\n",
       "      <td>16.559919</td>\n",
       "      <td>12.785998</td>\n",
       "      <td>110.211554</td>\n",
       "      <td>0.610537</td>\n",
       "      <td>2.751485</td>\n",
       "      <td>0.946656</td>\n",
       "      <td>8.385096</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>9.865513</td>\n",
       "      <td>385.372407</td>\n",
       "      <td>494.089496</td>\n",
       "      <td>9.024720</td>\n",
       "      <td>68140.203950</td>\n",
       "      <td>421.572801</td>\n",
       "      <td>71.788627</td>\n",
       "      <td>19.683659</td>\n",
       "      <td>229.168662</td>\n",
       "      <td>0.690870</td>\n",
       "      <td>5.243586</td>\n",
       "      <td>5.745028</td>\n",
       "      <td>21.412443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>-3.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>561.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>2802.000000</td>\n",
       "      <td>33.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>40.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>3.000000</td>\n",
       "      <td>34.000000</td>\n",
       "      <td>17.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10082.000000</td>\n",
       "      <td>104.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>114.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>10.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1900.000000</td>\n",
       "      <td>257675.000000</td>\n",
       "      <td>65535.000000</td>\n",
       "      <td>563.000000</td>\n",
       "      <td>23159456.000000</td>\n",
       "      <td>367553.000000</td>\n",
       "      <td>56311.000000</td>\n",
       "      <td>5064.000000</td>\n",
       "      <td>29019.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>165.000000</td>\n",
       "      <td>1881.000000</td>\n",
       "      <td>7393.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   f1              f2              f3              f4  \\\n",
       "count  2756813.000000  4999999.000000  3906401.000000  3853777.000000   \n",
       "mean         3.550075       98.595417       30.839373        7.429061   \n",
       "std          9.865513      385.372407      494.089496        9.024720   \n",
       "min          0.000000       -3.000000        0.000000        0.000000   \n",
       "25%          0.000000        0.000000        2.000000        2.000000   \n",
       "50%          1.000000        2.000000        6.000000        4.000000   \n",
       "75%          3.000000       34.000000       17.000000       10.000000   \n",
       "max       1900.000000   257675.000000    65535.000000      563.000000   \n",
       "\n",
       "                    f5              f6              f7              f8  \\\n",
       "count   4863896.000000  3887221.000000  4788996.000000  4997037.000000   \n",
       "mean      18112.661813      118.854952       16.559919       12.785998   \n",
       "std       68140.203950      421.572801       71.788627       19.683659   \n",
       "min           0.000000        0.000000        0.000000        0.000000   \n",
       "25%         561.000000        8.000000        1.000000        2.000000   \n",
       "50%        2802.000000       33.000000        3.000000        7.000000   \n",
       "75%       10082.000000      104.000000       12.000000       19.000000   \n",
       "max    23159456.000000   367553.000000    56311.000000     5064.000000   \n",
       "\n",
       "                   f9             f10             f11             f12  \\\n",
       "count  4788996.000000  2756813.000000  4788996.000000  1177668.000000   \n",
       "mean       110.211554        0.610537        2.751485        0.946656   \n",
       "std        229.168662        0.690870        5.243586        5.745028   \n",
       "min          0.000000        0.000000        0.000000        0.000000   \n",
       "25%         11.000000        0.000000        1.000000        0.000000   \n",
       "50%         40.000000        1.000000        1.000000        0.000000   \n",
       "75%        114.000000        1.000000        3.000000        0.000000   \n",
       "max      29019.000000        9.000000      165.000000     1881.000000   \n",
       "\n",
       "                  f13  \n",
       "count  3853777.000000  \n",
       "mean         8.385096  \n",
       "std         21.412443  \n",
       "min          0.000000  \n",
       "25%          2.000000  \n",
       "50%          4.000000  \n",
       "75%         10.000000  \n",
       "max       7393.000000  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_columns = list(df.columns)\n",
    "integer_cols = all_columns[:13]\n",
    "df[integer_cols].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create files for each histogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def m_count_distinct(col):\n",
    "    \"\"\"\n",
    "        count distinct values in all columns\n",
    "        @param col: numpy 1D array\n",
    "        @return: dictionary of value, freq\n",
    "    \"\"\"\n",
    "    d = {}\n",
    "    for x in list(col):\n",
    "        if type(x) == np.float64 and np.isnan(x):\n",
    "            k = 'nan-' + col\n",
    "            d[k] = d.get(k, 0) + 1\n",
    "        else:\n",
    "            d[x] = d.get(x, 0) + 1\n",
    "    return d\n",
    "\n",
    "\n",
    "# ==== create file from result of each freq count ===\n",
    "for col in all_columns:\n",
    "    filepath = 'histo-file/' + col + '.txt'\n",
    "    if (exists(filepath)):\n",
    "        print filepath + \" already created.\"\n",
    "    else:\n",
    "        freq_count = m_count_distinct(df[col].values)\n",
    "        with open(filepath, 'w') as f:\n",
    "            for key, value in freq_count.items():\n",
    "                row = str(key) + \",\" + str(value) + \"\\n\"\n",
    "                f.write(row)\n",
    "        print \"Newly created file:\", filepath"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create weighted distribution for each histogram and store in files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for col in categorical_cols:\n",
    "    filepath = \"histo-weight/\" + col + \".txt\"\n",
    "    if (exists(filepath)):\n",
    "        print filepath + \" already created.\"\n",
    "    else:\n",
    "        dfpath = \"histo-file/\" + col + \".txt\"\n",
    "        histo_df = pd.read_csv(dfpath, header=None, names=[\"val\", \"freq\"])\n",
    "        histo_df.freq = histo_df.freq / len(df)\n",
    "        histo_df.columns = [\"val\", \"weight\"]\n",
    "        histo_df.to_csv(filepath)\n",
    "        print \"Newly created file:\" + filepath"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot histograms and store files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for col in all_columns:\n",
    "    filepath = \"histo-file/\" + col + \".txt\"\n",
    "    histo_df = pd.read_csv(filepath, header=None, names=[\"val\", \"freq\"])\n",
    "    ax = histo_df.plot(x='val', y='freq', logy='True', title=col, xlim=(0))\n",
    "    fig = ax.get_figure()\n",
    "    fig.savefig('second-histo-img/' + col + '.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Normalize integer columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>f1</th>\n",
       "      <th>f2</th>\n",
       "      <th>f3</th>\n",
       "      <th>f4</th>\n",
       "      <th>f5</th>\n",
       "      <th>f6</th>\n",
       "      <th>f7</th>\n",
       "      <th>f8</th>\n",
       "      <th>f9</th>\n",
       "      <th>f10</th>\n",
       "      <th>f11</th>\n",
       "      <th>f12</th>\n",
       "      <th>f13</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.001053</td>\n",
       "      <td>0.000012</td>\n",
       "      <td>0.000671</td>\n",
       "      <td>0.001776</td>\n",
       "      <td>4.404249e-06</td>\n",
       "      <td>0.000022</td>\n",
       "      <td>0.000036</td>\n",
       "      <td>0.000395</td>\n",
       "      <td>0.000138</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.006061</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000541</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.001053</td>\n",
       "      <td>0.000012</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>0.024867</td>\n",
       "      <td>3.311822e-05</td>\n",
       "      <td>0.000242</td>\n",
       "      <td>0.000071</td>\n",
       "      <td>0.000395</td>\n",
       "      <td>0.008443</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.018182</td>\n",
       "      <td>0.001595</td>\n",
       "      <td>0.006087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.003477</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.896418e-04</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.001579</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>8.635781e-08</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000053</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.006061</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.537263e-04</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000207</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         f1        f2        f3        f4            f5        f6        f7  \\\n",
       "0  0.001053  0.000012  0.000671  0.001776  4.404249e-06  0.000022  0.000036   \n",
       "1  0.001053  0.000012  0.000015  0.024867  3.311822e-05  0.000242  0.000071   \n",
       "2       NaN  0.003477       NaN       NaN  1.896418e-04       NaN  0.000000   \n",
       "3  0.001579  0.000008       NaN  0.000000  8.635781e-08  0.000000  0.000053   \n",
       "4       NaN  0.000008       NaN       NaN  5.537263e-04       NaN  0.000000   \n",
       "\n",
       "         f8        f9       f10       f11       f12       f13  \n",
       "0  0.000395  0.000138  0.111111  0.006061       NaN  0.000541  \n",
       "1  0.000395  0.008443  0.111111  0.018182  0.001595  0.006087  \n",
       "2  0.000000  0.000000       NaN  0.000000       NaN       NaN  \n",
       "3  0.000000  0.000000  0.111111  0.006061       NaN  0.000000  \n",
       "4  0.000000  0.000207       NaN  0.000000       NaN       NaN  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_norm = df[integer_cols].apply(lambda x: (x - x.min()) / (x.max() - x.min()))\n",
    "df_norm.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Copy categorical columns into normalized dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "categorical_cols = all_columns[13:]\n",
    "df_norm[categorical_cols] = df[categorical_cols]\n",
    "df_norm.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Export normalized dataframe to file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_norm.to_csv(\"normalized_full_df.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compute one-hot weighted distribution of features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>f1</th>\n",
       "      <th>f2</th>\n",
       "      <th>f3</th>\n",
       "      <th>f4</th>\n",
       "      <th>f5</th>\n",
       "      <th>f6</th>\n",
       "      <th>f7</th>\n",
       "      <th>f8</th>\n",
       "      <th>f9</th>\n",
       "      <th>...</th>\n",
       "      <th>f30</th>\n",
       "      <th>f31</th>\n",
       "      <th>f32</th>\n",
       "      <th>f33</th>\n",
       "      <th>f34</th>\n",
       "      <th>f35</th>\n",
       "      <th>f36</th>\n",
       "      <th>f37</th>\n",
       "      <th>f38</th>\n",
       "      <th>f39</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.001053</td>\n",
       "      <td>0.000012</td>\n",
       "      <td>0.000671</td>\n",
       "      <td>0.001776</td>\n",
       "      <td>4.404249e-06</td>\n",
       "      <td>0.000022</td>\n",
       "      <td>0.000036</td>\n",
       "      <td>0.000395</td>\n",
       "      <td>0.000138</td>\n",
       "      <td>...</td>\n",
       "      <td>07c540c4</td>\n",
       "      <td>b04e4670</td>\n",
       "      <td>21ddcdc9</td>\n",
       "      <td>5840adea</td>\n",
       "      <td>60f6221e</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3a171ecb</td>\n",
       "      <td>43f13e8b</td>\n",
       "      <td>e8b83407</td>\n",
       "      <td>731c3655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.001053</td>\n",
       "      <td>0.000012</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>0.024867</td>\n",
       "      <td>3.311822e-05</td>\n",
       "      <td>0.000242</td>\n",
       "      <td>0.000071</td>\n",
       "      <td>0.000395</td>\n",
       "      <td>0.008443</td>\n",
       "      <td>...</td>\n",
       "      <td>8efede7f</td>\n",
       "      <td>3412118d</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>e587c466</td>\n",
       "      <td>ad3062eb</td>\n",
       "      <td>3a171ecb</td>\n",
       "      <td>3b183c5c</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.003477</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.896418e-04</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1e88c74f</td>\n",
       "      <td>74ef3502</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6b3a5ca6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3a171ecb</td>\n",
       "      <td>9117a34a</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0.001579</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>8.635781e-08</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000053</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1e88c74f</td>\n",
       "      <td>26b3c7a7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>21c9516a</td>\n",
       "      <td>NaN</td>\n",
       "      <td>32c7478e</td>\n",
       "      <td>b34f3128</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.537263e-04</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000207</td>\n",
       "      <td>...</td>\n",
       "      <td>776ce399</td>\n",
       "      <td>92555263</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>242bb710</td>\n",
       "      <td>8ec974f4</td>\n",
       "      <td>be7c41b4</td>\n",
       "      <td>72c78f11</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 40 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0        f1        f2        f3        f4            f5        f6  \\\n",
       "0           0  0.001053  0.000012  0.000671  0.001776  4.404249e-06  0.000022   \n",
       "1           1  0.001053  0.000012  0.000015  0.024867  3.311822e-05  0.000242   \n",
       "2           2       NaN  0.003477       NaN       NaN  1.896418e-04       NaN   \n",
       "3           3  0.001579  0.000008       NaN  0.000000  8.635781e-08  0.000000   \n",
       "4           4       NaN  0.000008       NaN       NaN  5.537263e-04       NaN   \n",
       "\n",
       "         f7        f8        f9    ...          f30       f31       f32  \\\n",
       "0  0.000036  0.000395  0.000138    ...     07c540c4  b04e4670  21ddcdc9   \n",
       "1  0.000071  0.000395  0.008443    ...     8efede7f  3412118d       NaN   \n",
       "2  0.000000  0.000000  0.000000    ...     1e88c74f  74ef3502       NaN   \n",
       "3  0.000053  0.000000  0.000000    ...     1e88c74f  26b3c7a7       NaN   \n",
       "4  0.000000  0.000000  0.000207    ...     776ce399  92555263       NaN   \n",
       "\n",
       "        f33       f34       f35       f36       f37       f38       f39  \n",
       "0  5840adea  60f6221e       NaN  3a171ecb  43f13e8b  e8b83407  731c3655  \n",
       "1       NaN  e587c466  ad3062eb  3a171ecb  3b183c5c       NaN       NaN  \n",
       "2       NaN  6b3a5ca6       NaN  3a171ecb  9117a34a       NaN       NaN  \n",
       "3       NaN  21c9516a       NaN  32c7478e  b34f3128       NaN       NaN  \n",
       "4       NaN  242bb710  8ec974f4  be7c41b4  72c78f11       NaN       NaN  \n",
       "\n",
       "[5 rows x 40 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_onehot = pd.read_csv('normalized_full_df.csv')\n",
    "df_onehot.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### create a giant dictionary containing all categorical features and their weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5312649\n"
     ]
    }
   ],
   "source": [
    "d = {}\n",
    "categorical_cols = ['f' + str(num) for num in range(14,40)]\n",
    "for col in categorical_cols:\n",
    "    filepath = \"histo-weight/\" + col + \".txt\"\n",
    "    # print filepath\n",
    "    with open(filepath) as f:\n",
    "        reader = csv.reader(f)\n",
    "        for ignore, val, weight in reader:\n",
    "            d[val] = weight\n",
    "print len(d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### change every hashed string to their weighted values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for col in categorical_cols:\n",
    "    df_onehot[col] = df_onehot[col].apply(lambda x: d.get(x))\n",
    "df_onehot.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Export weighted onehot encoded dataframe to file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_onehot.to_csv('one-hot-ready.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Select features to be used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cols_to_keep = all_columns[10:13]\n",
    "#df_norm[cols_to_keep].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model and Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4999999, 39)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>f1</th>\n",
       "      <th>f2</th>\n",
       "      <th>f3</th>\n",
       "      <th>f4</th>\n",
       "      <th>f5</th>\n",
       "      <th>f6</th>\n",
       "      <th>f7</th>\n",
       "      <th>f8</th>\n",
       "      <th>f9</th>\n",
       "      <th>f10</th>\n",
       "      <th>...</th>\n",
       "      <th>f30</th>\n",
       "      <th>f31</th>\n",
       "      <th>f32</th>\n",
       "      <th>f33</th>\n",
       "      <th>f34</th>\n",
       "      <th>f35</th>\n",
       "      <th>f36</th>\n",
       "      <th>f37</th>\n",
       "      <th>f38</th>\n",
       "      <th>f39</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.001053</td>\n",
       "      <td>0.000012</td>\n",
       "      <td>0.000671</td>\n",
       "      <td>0.001776</td>\n",
       "      <td>4.404249e-06</td>\n",
       "      <td>0.000022</td>\n",
       "      <td>0.000036</td>\n",
       "      <td>0.000395</td>\n",
       "      <td>0.000138</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>...</td>\n",
       "      <td>0.129438</td>\n",
       "      <td>0.007669</td>\n",
       "      <td>0.332528</td>\n",
       "      <td>0.180496</td>\n",
       "      <td>5.692601e-03</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.203219</td>\n",
       "      <td>0.005693</td>\n",
       "      <td>0.114505</td>\n",
       "      <td>0.005693</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.001053</td>\n",
       "      <td>0.000012</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>0.024867</td>\n",
       "      <td>3.311822e-05</td>\n",
       "      <td>0.000242</td>\n",
       "      <td>0.000071</td>\n",
       "      <td>0.000395</td>\n",
       "      <td>0.008443</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>...</td>\n",
       "      <td>0.042881</td>\n",
       "      <td>0.000741</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.182160e-02</td>\n",
       "      <td>0.136544</td>\n",
       "      <td>0.203219</td>\n",
       "      <td>0.047778</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.003477</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.896418e-04</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.041832</td>\n",
       "      <td>0.005630</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.000000e-07</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.203219</td>\n",
       "      <td>0.018353</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.001579</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>8.635781e-08</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000053</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>...</td>\n",
       "      <td>0.041832</td>\n",
       "      <td>0.000500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.163001e-03</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.434402</td>\n",
       "      <td>0.046772</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.537263e-04</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000207</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.052262</td>\n",
       "      <td>0.001148</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.944002e-04</td>\n",
       "      <td>0.006118</td>\n",
       "      <td>0.054689</td>\n",
       "      <td>0.001206</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 39 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         f1        f2        f3        f4            f5        f6        f7  \\\n",
       "0  0.001053  0.000012  0.000671  0.001776  4.404249e-06  0.000022  0.000036   \n",
       "1  0.001053  0.000012  0.000015  0.024867  3.311822e-05  0.000242  0.000071   \n",
       "2       NaN  0.003477       NaN       NaN  1.896418e-04       NaN  0.000000   \n",
       "3  0.001579  0.000008       NaN  0.000000  8.635781e-08  0.000000  0.000053   \n",
       "4       NaN  0.000008       NaN       NaN  5.537263e-04       NaN  0.000000   \n",
       "\n",
       "         f8        f9       f10    ...          f30       f31       f32  \\\n",
       "0  0.000395  0.000138  0.111111    ...     0.129438  0.007669  0.332528   \n",
       "1  0.000395  0.008443  0.111111    ...     0.042881  0.000741       NaN   \n",
       "2  0.000000  0.000000       NaN    ...     0.041832  0.005630       NaN   \n",
       "3  0.000000  0.000000  0.111111    ...     0.041832  0.000500       NaN   \n",
       "4  0.000000  0.000207       NaN    ...     0.052262  0.001148       NaN   \n",
       "\n",
       "        f33           f34       f35       f36       f37       f38       f39  \n",
       "0  0.180496  5.692601e-03       NaN  0.203219  0.005693  0.114505  0.005693  \n",
       "1       NaN  1.182160e-02  0.136544  0.203219  0.047778       NaN       NaN  \n",
       "2       NaN  2.000000e-07       NaN  0.203219  0.018353       NaN       NaN  \n",
       "3       NaN  5.163001e-03       NaN  0.434402  0.046772       NaN       NaN  \n",
       "4       NaN  8.944002e-04  0.006118  0.054689  0.001206       NaN       NaN  \n",
       "\n",
       "[5 rows x 39 columns]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#X = pd.read_csv('one-hot-ready.csv')\n",
    "print X.shape\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape: (4999999, 1)\n",
      "   predict\n",
      "0        0\n",
      "1        0\n",
      "2        0\n",
      "3        0\n",
      "4        0\n"
     ]
    }
   ],
   "source": [
    "y = pd.read_csv('y_for_train5M.csv', header=None, names=[\"predict\"])\n",
    "print \"shape:\", y.shape\n",
    "print y.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Handle NaN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cX = X.fillna(0)\n",
    "cy = y.fillna(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### convert y to 1D array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cy = cy.predict.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "model = LogisticRegression()\n",
    "model.fit(cX, cy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.74802934960586998"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.score(cX,cy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "########### ================ STOPPP: still editing code below ####################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split up the data set into test and training sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.cross_validation import train_test_split\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=1)\n",
    "testLogRModel = LogisticRegression()\n",
    "testLogRModel.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "testLogRModel.score(X,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict class labels for the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "predicted = testLogRModel.predict(x_test)\n",
    "print predicted"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AUC score from ROC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "print \"accuracy:\", metrics.accuracy_score(y_test, predicted)\n",
    "# print \"auc:\", metrics.roc_auc_score(y_test, predicted)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Perform cross validation using n folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.cross_validation import cross_val_score\n",
    "#n = 5\n",
    "#scores = cross_val_score(LogisticRegression(), X, y, scoring='accuracy')\n",
    "#print scores\n",
    "#print scores.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "clf_random_forest = RandomForestClassifier(n_estimators=10)\n",
    "clf_random_forest.fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "clf_random_forest.score(X,y)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
