{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recommendation System Datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "This notebook uses the following datasets:\n",
    "\n",
    "- [MovieLens 10M data set](http://grouplens.org/datasets/movielens/10m/)\n",
    "- [MovieLens 22M data set](http://grouplens.org/datasets/movielens/latest/)\n",
    "- [Million song data set](http://labrosa.ee.columbia.edu/millionsong/tasteprofile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split dataset into 60-20-20 train-validate-test partitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "def exists(filepath):\n",
    "    return os.path.exists(filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Already created files: train60.dat, validation20.dat, test20.dat\n"
     ]
    }
   ],
   "source": [
    "if (exists('ml-10M100K/train60.dat') and exists('ml-10M100K/validation20.dat') and exists('ml-10M100K/test20.dat')):\n",
    "    print \"Already created files: train60.dat, validation20.dat, test20.dat\"    \n",
    "\n",
    "else:\n",
    "    # sort by timestamp (4th column)\n",
    "    print 'sorting file...'\n",
    "    !sort -t ':' -k4 ml-10M100K/ratings.dat > ml-10M100K/new_ratings.dat \n",
    "    print \"sorting complete.\"\n",
    "    \n",
    "    # split into 5 parts of 2 million each: train(3 parts), validation (1 part), test (1 part)\n",
    "    print \"splitting file...\"\n",
    "    !split -l 2000000 ml-10M100K/new_ratings.dat ff\n",
    "    !cat ffaa ffab ffac > ml-10M100K/train60.dat\n",
    "    !mv ffad ml-10M100K/validation20.dat\n",
    "    !mv ffae ml-10M100K/test20.dat\n",
    "    \n",
    "    # remove tmp files used to create partitions\n",
    "    !rm new_ratings.dat ff*\n",
    "    print \"splitting complete.\"    \n",
    "    print \"Newly created files: train60.dat, validation20.dat, test20.dat\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using train data, learn ALS model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import contextlib\n",
    "from math import sqrt\n",
    "from operator import add\n",
    "import sys\n",
    "from pyspark.mllib.recommendation import ALS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def parse_rating(line):\n",
    "    \"\"\"\n",
    "    Parses a rating record that's in MovieLens format.\n",
    "    \n",
    "    :param str line: userId::movieId::rating::timestamp\n",
    "    \"\"\"\n",
    "    fields = line.strip().split(\"::\")\n",
    "\n",
    "    return (int(fields[0]),   # User ID\n",
    "            int(fields[1]),   # Movie ID\n",
    "            float(fields[2])) # Rating\n",
    "\n",
    "\n",
    "def compute_rmse(model, data, validationCount):\n",
    "    \"\"\"\n",
    "    Compute RMSE (Root Mean Squared Error).\n",
    "    :param object model\n",
    "    :param list data\n",
    "    :param integer validation_count\n",
    "    \"\"\"\n",
    "    predictions = model.predictAll(data.map(lambda x: (x[0], x[1])))\n",
    "    predictionsAndRatings = \\\n",
    "        predictions.map(lambda x: ((x[0], x[1]), x[2])) \\\n",
    "                   .join(data.map(lambda x: ((x[0], x[1]), x[2]))) \\\n",
    "                   .values()\n",
    "    return sqrt(\n",
    "        predictionsAndRatings.map(\n",
    "            lambda x: (x[0] - x[1]) ** 2\n",
    "        ).reduce(add) / float(validationCount)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "training = sc.textFile('ml-10M100K/train60.dat') \\\n",
    "         .filter(lambda x: x and len(x.split('::')) == 4) \\\n",
    "         .map(parse_rating)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "validation = sc.textFile('ml-10M100K/validation20.dat') \\\n",
    "         .filter(lambda x: x and len(x.split('::')) == 4) \\\n",
    "         .map(parse_rating)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test = sc.textFile('ml-10M100K/test20.dat') \\\n",
    "         .filter(lambda x: x and len(x.split('::')) == 4) \\\n",
    "         .map(parse_rating)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6000000"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainCount = training.count()\n",
    "trainCount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2000000"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validationCount = validation.count()\n",
    "validationCount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2000000"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testCount = test.count()\n",
    "testCount"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train ALS model using different regularization parameter and latent factors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rank=10, Lambda=0.01, RMSE=1.06049775091\n",
      "Rank=10, Lambda=0.1, RMSE=1.10979440812\n",
      "Rank=10, Lambda=1.0, RMSE=1.95801505852\n",
      "Rank=10, Lambda=10.0, RMSE=3.99960898089\n",
      "Rank=20, Lambda=0.01, RMSE=1.07348413238\n",
      "Rank=20, Lambda=0.1, RMSE=1.14287691247\n",
      "Rank=20, Lambda=1.0, RMSE=1.95987810731\n",
      "Rank=20, Lambda=10.0, RMSE=3.99960898089\n",
      "Rank=30, Lambda=0.01, RMSE=1.08488028136\n",
      "Rank=30, Lambda=0.1, RMSE=1.1275414034\n",
      "Rank=30, Lambda=1.0, RMSE=1.95889910186\n",
      "Rank=30, Lambda=10.0, RMSE=3.99960898089\n",
      "Rank=40, Lambda=0.01, RMSE=1.08504936949\n",
      "Rank=40, Lambda=0.1, RMSE=1.16572274978\n",
      "Rank=40, Lambda=1.0, RMSE=1.95928678985\n",
      "Rank=40, Lambda=10.0, RMSE=3.99960898089\n",
      "Rank=50, Lambda=0.01, RMSE=1.10281105899\n",
      "Rank=50, Lambda=0.1, RMSE=1.18677347337\n",
      "Rank=50, Lambda=1.0, RMSE=1.95958789238\n",
      "Rank=50, Lambda=10.0, RMSE=3.99960898089\n"
     ]
    }
   ],
   "source": [
    "rank_list = [10, 20, 30, 40, 50] # latent factor\n",
    "lamda_list = [0.01, 0.1, 1.0, 10.0] # regularization parameter\n",
    "iterations = 10\n",
    "chosenModel = None\n",
    "smallestRMSE = 9999999\n",
    "\n",
    "for rank in rank_list:\n",
    "    for lamda in lamda_list:\n",
    "        model = ALS.train(training, rank, iterations, lamda)\n",
    "        rmse = compute_rmse(model, validation, validationCount)\n",
    "        \n",
    "        if rmse < smallestRMSE:\n",
    "            smallestRMSE = rmse\n",
    "            chosenModel = model\n",
    "\n",
    "        print 'Rank={}, Lambda={}, RMSE={}'.format(rank, lamda, rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "chosenModel.save(sc, 'chosenModel')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The smallest RMSE is: 1.06\n"
     ]
    }
   ],
   "source": [
    "print 'The smallest RMSE is:{0: .2f}'.format(smallestRMSE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use chosen model with test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final error metric using test set = 1.87\n"
     ]
    }
   ],
   "source": [
    "testRMSE = compute_rmse(chosenModel, test, testCount)\n",
    "print 'Final error metric using test set ={0: .2f}'.format(testRMSE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generate_recommendations(model, ratingsFile):\n",
    "    prediction = []\n",
    "    return prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ratings = sc.textFile('ml-10M100K/ratings.dat') \\\n",
    "         .filter(lambda x: x and len(x.split('::')) == 4) \\\n",
    "         .map(parse_rating)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1, 122, 5.0), (1, 185, 5.0), (1, 231, 5.0)]"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratings.take(3) # userID::movieID::ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "userRatings = ratings.filter(lambda x: x[0] == 1) # get only movie ratings for user with userid=1\n",
    "userRatings.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PythonRDD[2899] at RDD at PythonRDD.scala:43"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "userRatings"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'1::122::5::838985046', u'1::185::5::838983525', u'1::231::5::838983392']"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratings = sc.textFile('ml-10M100K/ratings.dat')\n",
    "ratings.take(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on method train in module pyspark.mllib.recommendation:\n",
      "\n",
      "train(cls, ratings, rank, iterations=5, lambda_=0.01, blocks=-1, nonnegative=False, seed=None) method of __builtin__.type instance\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(ALS.train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Meaning of parameters\n",
    "\n",
    "- numBlocks is the number of blocks used to parallelize computation (set to -1 to auto-configure).\n",
    "- ***rank*** is the number of latent factors in the model.\n",
    "- iterations is the number of iterations to run.\n",
    "- ***lambda*** specifies the regularization parameter in ALS.\n",
    "- implicitPrefs specifies whether to use the explicit feedback ALS variant or one adapted for implicit feedback data.\n",
    "- alpha is a parameter applicable to the implicit feedback variant of ALS that governs the baseline confidence in preference observations.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(37746, 3409, 0.5), (37746, 175, 0.5), (51778, 5430, 0.5)]"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training.take(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(6352, 6787, 4.0), (26571, 1580, 4.0), (26571, 2115, 4.0)]"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validation.take(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(5337, 296, 4.0), (5337, 307, 4.0), (32329, 3745, 4.0)]"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.take(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train and Save ALS Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model = ALS.train(training, 10, 20, 0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.save(sc, 'myALSmodel')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Try model with validation set (user-product pairs needed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on method predictAll in module pyspark.mllib.recommendation:\n",
      "\n",
      "predictAll(self, user_product) method of pyspark.mllib.recommendation.MatrixFactorizationModel instance\n",
      "    Returns a list of predicted ratings for input user and product pairs.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(model.predictAll)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(6352, 6787), (26571, 1580), (26571, 2115)]"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validation_pair = validation.map(lambda x: (x[0], x[1]))\n",
    "validation_pair.take(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Rating(user=57436, product=1356, rating=2.9622857548829815),\n",
       " Rating(user=57436, product=648, rating=2.7055366122842517),\n",
       " Rating(user=57436, product=260, rating=2.618657352015365)]"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = model.predictAll(validation_pair)\n",
    "predictions.take(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(57436, 1356, 2.9622857548829815),\n",
       " (57436, 648, 2.7055366122842517),\n",
       " (57436, 260, 2.618657352015365)]"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = predictions.map(lambda x: (x[0], x[1], x[2]))\n",
    "predictions.take(3)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
